{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I learn this RNN model on Thibault Neveu's channel : \n",
    "His videos : https://www.youtube.com/channel/UCVso5UVvQeGAuwbksmA95iA\n",
    "His GitHub : https://github.com/thibo73800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289\n",
      "ABCDEFGGFEDCBABG\n",
      "AACDEFGGEDCBADDE\n",
      "DDDBEGFCADFBEAGE\n",
      "ACDBFFFEADBGEAFA\n",
      "BBFEBGAEDBCEAFCE\n",
      "GEABCDEAFEABCDGB\n",
      "BDECABDECFFEADDG\n",
      "GEBDFEACBGEDCAEF\n",
      "GEABFCDEBGEACGBE\n",
      "GBEAFCEBDAEFCEAG\n",
      "GGFFCCEEAACBFEAD\n",
      "FEABCDEAAGABCEED\n",
      "FFEECCBDBEGACEDB\n",
      "GEBCAFEDBEACFBEC\n",
      "GBCEACDEBAGEBDEA\n",
      "GBECDEAFECBDEBFE\n",
      "ACDEBDECAFBECDEB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"TEST.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(len(text))\n",
    "\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 {'e', '\\n', 'f', 'g', 'd', 'a', 'c', 'b'}\n",
      "abcdefggfedcbabg\n",
      "aacdefggedcbadde\n",
      "dddbegfcadfbeage\n",
      "acdbfffeadbgeafa\n",
      "bbfebgaedbceafce\n",
      "geabcdeafeabcdgb\n",
      "bdecabdecffeaddg\n",
      "gebdfeacbgedcaef\n",
      "geabfcdebgeacgbe\n",
      "gbeafcebdaefceag\n",
      "ggffcceeaacbfead\n",
      "feabcdeaagabceed\n",
      "ffeeccbdbegacedb\n",
      "gebcafedbeacfbec\n",
      "gbceacdebagebdea\n",
      "gbecdeafecbdebfe\n",
      "acdebdecafbecdeb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = text.lower()\n",
    "vocab = set(text)\n",
    "print(len(vocab), vocab)\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_to_int {'e': 0, '\\n': 1, 'f': 2, 'g': 3, 'd': 4, 'a': 5, 'c': 6, 'b': 7}\n",
      "\n",
      "int_to_vocab {0: 'e', 1: '\\n', 2: 'f', 3: 'g', 4: 'd', 5: 'a', 6: 'c', 7: 'b'}\n",
      "\n",
      "int for e: 0\n",
      "letter for 0: e\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "vocab_to_int = {l:i for i,l in enumerate(vocab)}\n",
    "int_to_vocab = {i:l for i,l in enumerate(vocab)}\n",
    "\n",
    "print(\"vocab_to_int\", vocab_to_int)\n",
    "print()\n",
    "print(\"int_to_vocab\", int_to_vocab)\n",
    "\n",
    "print(\"\\nint for e:\", vocab_to_int[\"e\"])\n",
    "int_for_e = vocab_to_int[\"e\"]\n",
    "print(\"letter for %s: %s\" % (vocab_to_int[\"e\"], int_to_vocab[int_for_e]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 7, 6, 4, 0, 2, 3, 3, 2, 0, 4, 6, 7, 5, 7, 3, 1, 5, 5, 6, 4, 0, 2, 3, 3, 0, 4, 6, 7, 5, 4, 4, 0, 1, 4, 4, 4, 7, 0, 3, 2, 6, 5, 4, 2, 7, 0, 5, 3, 0, 1, 5, 6, 4, 7, 2, 2, 2, 0, 5, 4, 7, 3, 0, 5, 2, 5, 1, 7, 7, 2, 0, 7, 3, 5, 0, 4, 7, 6, 0, 5, 2, 6, 0, 1, 3, 0, 5, 7, 6, 4, 0, 5, 2, 0, 5, 7, 6, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "encoded = [vocab_to_int[l] for l in text]\n",
    "encoded_sentence = encoded[:100]\n",
    "\n",
    "print(encoded_sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'g', 'f', 'e', 'd', 'c', 'b', 'a', 'b', 'g', '\\n', 'a', 'a', 'c', 'd', 'e', 'f', 'g', 'g', 'e', 'd', 'c', 'b', 'a', 'd', 'd', 'e', '\\n', 'd', 'd', 'd', 'b', 'e', 'g', 'f', 'c', 'a', 'd', 'f', 'b', 'e', 'a', 'g', 'e', '\\n', 'a', 'c', 'd', 'b', 'f', 'f', 'f', 'e', 'a', 'd', 'b', 'g', 'e', 'a', 'f', 'a', '\\n', 'b', 'b', 'f', 'e', 'b', 'g', 'a', 'e', 'd', 'b', 'c', 'e', 'a', 'f', 'c', 'e', '\\n', 'g', 'e', 'a', 'b', 'c', 'd', 'e', 'a', 'f', 'e', 'a', 'b', 'c', 'd', 'g']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "decoded_sentence = [int_to_vocab[i] for i in encoded_sentence]\n",
    "print(decoded_sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefggfedcbabg\n",
      "aacdefggedcbadde\n",
      "dddbegfcadfbeage\n",
      "acdbfffeadbgeafa\n",
      "bbfebgaedbceafce\n",
      "geabcdeafeabcdg\n"
     ]
    }
   ],
   "source": [
    "decoded_sentence = \"\".join(decoded_sentence)\n",
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs [5, 7, 6, 4, 0, 2, 3, 3, 2, 0]\n",
      "Targets [7, 6, 4, 0, 2, 3, 3, 2, 0, 4]\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = encoded, encoded[1:]\n",
    "\n",
    "print(\"Inputs\", inputs[:10])\n",
    "print(\"Targets\", targets[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 7. 6. 4. 0.] [7. 6. 4. 0. 2.]\n",
      "[3. 7. 3. 4. 3.] [7. 6. 4. 0. 2.]\n"
     ]
    }
   ],
   "source": [
    "def gen_batch(inputs, targets, seq_len, batch_size, noise=0):\n",
    "    # Size of each chunk\n",
    "    chuck_size = (len(inputs) -1)  // batch_size\n",
    "    # Numbef of sequence per chunk\n",
    "    sequences_per_chunk = chuck_size // seq_len\n",
    "\n",
    "    for s in range(0, sequences_per_chunk):\n",
    "        batch_inputs = np.zeros((batch_size, seq_len))\n",
    "        batch_targets = np.zeros((batch_size, seq_len))\n",
    "        for b in range(0, batch_size):\n",
    "            fr = (b*chuck_size)+(s*seq_len)\n",
    "            to = fr+seq_len\n",
    "            batch_inputs[b] = inputs[fr:to]\n",
    "            batch_targets[b] = inputs[fr+1:to+1]\n",
    "            \n",
    "            if noise > 0:\n",
    "                noise_indices = np.random.choice(seq_len, noise)\n",
    "                batch_inputs[b][noise_indices] = np.random.randint(0, vocab_size)\n",
    "            \n",
    "        yield batch_inputs, batch_targets\n",
    "\n",
    "for batch_inputs, batch_targets in gen_batch(inputs, targets, 5, 16, noise=0):\n",
    "    print(batch_inputs[0], batch_targets[0])\n",
    "    break\n",
    "\n",
    "for batch_inputs, batch_targets in gen_batch(inputs, targets, 5, 16, noise=3):\n",
    "    print(batch_inputs[0], batch_targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHot(tf.keras.layers.Layer):\n",
    "    def __init__(self, depth, **kwargs):\n",
    "        super(OneHot, self).__init__(**kwargs)\n",
    "        self.depth = depth\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return tf.one_hot(tf.cast(x, tf.int32), self.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 8)\n",
      "(16, 8, 8)\n",
      "Input letter is: 5.0\n",
      "One hot representation of the letter [0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "class RnnModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super(RnnModel, self).__init__()\n",
    "        # Convolutions\n",
    "        self.one_hot = OneHot(len(vocab))\n",
    "    def call(self, inputs):\n",
    "        output = self.one_hot(inputs)\n",
    "        return output\n",
    "\n",
    "batch_inputs, batch_targets = next(gen_batch(inputs, targets, 8, 16))\n",
    "\n",
    "print(batch_inputs.shape)\n",
    "\n",
    "model = RnnModel(len(vocab))\n",
    "output = model.predict(batch_inputs)\n",
    "\n",
    "print(output.shape)\n",
    "\n",
    "#print(output)\n",
    "\n",
    "print(\"Input letter is:\", batch_inputs[0][0])\n",
    "print(\"One hot representation of the letter\", output[0][0])\n",
    "\n",
    "#assert(output[int(batch_inputs[0][0])]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\JDC\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "tf_inputs = tf.keras.Input(shape=(None,), batch_size=16)\n",
    "one_hot = OneHot(len(vocab))(tf_inputs)\n",
    "rnn_layer1 = tf.keras.layers.LSTM(128, return_sequences=True, stateful=True)(one_hot)\n",
    "rnn_layer2 = tf.keras.layers.LSTM(128, return_sequences=True, stateful=True)(rnn_layer1)\n",
    "hidden_layer = tf.keras.layers.Dense(128, activation=\"relu\")(rnn_layer2)\n",
    "outputs = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")(hidden_layer)\n",
    "model = tf.keras.Model(inputs=tf_inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = 'categorical_crossentropy'\n",
    "optimizer = 'rmsprop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_object(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(targets, predictions)\n",
    "\n",
    "def predict(inputs):\n",
    "    predictions = model(inputs)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 399, Train Loss: Tensor(\"div_no_nan_798:0\", shape=(), dtype=float32), Train Accuracy: Tensor(\"mul_399:0\", shape=(), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model.reset_states()\n",
    "\n",
    "for epoch in range(400):\n",
    "    for batch_inputs, batch_targets in gen_batch(inputs, targets, 20, 16, noise=3):\n",
    "        train_step(batch_inputs, batch_targets)\n",
    "    template = '\\r Epoch {}, Train Loss: {}, Train Accuracy: {}'\n",
    "    print(template.format(epoch, train_loss.result(), train_accuracy.result()*100), end=\"\")\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model.save(\"model_rnn.h5\")\n",
    "with open(\"model_rnn_vocab_to_int\", \"w\") as f:\n",
    "    f.write(json.dumps(vocab_to_int))\n",
    "with open(\"model_rnn_int_to_vocab\", \"w\") as f:\n",
    "    f.write(json.dumps(int_to_vocab))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeeeeeeeee\n",
      "\n",
      "=====================\n",
      "\n",
      "eeeeeeeeee\n",
      "\n",
      "=====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "model.reset_states()\n",
    "size_music = 10\n",
    "poetries = np.zeros((16, size_music, 1))\n",
    "sequences = np.zeros((16, 20))\n",
    "for b in range(2):\n",
    "    rd = np.random.randint(0, len(inputs) - 20)\n",
    "    sequences[b] = inputs[rd:rd+20]\n",
    "\n",
    "for i in range(size_music+1):\n",
    "    if i > 0:\n",
    "        poetries[:,i-1,:] = sequences\n",
    "    softmax = predict(sequences)\n",
    "    # Set the next sequences\n",
    "    sequences = np.zeros((16, 1))\n",
    "    for b in range(2):\n",
    "        argsort = np.argsort(softmax[b][0])\n",
    "        argsort = argsort[::-1]\n",
    "        # Select one of the strongest 4 proposals\n",
    "        sequences[b] = argsort[0]\n",
    "\n",
    "for b in range(2):\n",
    "    sentence = \"\".join([int_to_vocab[i[0]] for i in poetries[b]])\n",
    "    print(sentence)\n",
    "    print(\"\\n=====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
